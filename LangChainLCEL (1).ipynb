{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b18ea38-4fd4-409b-b1f8-547e0c72bbc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ibm-watsonx-ai==1.0.8 in /home/jupyterlab/.local/lib/python3.12/site-packages (1.0.8)\n",
      "Requirement already satisfied: requests in /home/jupyterlab/.local/lib/python3.12/site-packages (from ibm-watsonx-ai==1.0.8) (2.32.2)\n",
      "Requirement already satisfied: urllib3 in /opt/conda/lib/python3.12/site-packages (from ibm-watsonx-ai==1.0.8) (2.3.0)\n",
      "Requirement already satisfied: pandas<2.2.0,>=0.24.2 in /home/jupyterlab/.local/lib/python3.12/site-packages (from ibm-watsonx-ai==1.0.8) (2.1.4)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.12/site-packages (from ibm-watsonx-ai==1.0.8) (2024.12.14)\n",
      "Requirement already satisfied: lomond in /home/jupyterlab/.local/lib/python3.12/site-packages (from ibm-watsonx-ai==1.0.8) (0.3.3)\n",
      "Requirement already satisfied: tabulate in /home/jupyterlab/.local/lib/python3.12/site-packages (from ibm-watsonx-ai==1.0.8) (0.9.0)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.12/site-packages (from ibm-watsonx-ai==1.0.8) (24.2)\n",
      "Requirement already satisfied: ibm-cos-sdk<2.14.0,>=2.12.0 in /home/jupyterlab/.local/lib/python3.12/site-packages (from ibm-watsonx-ai==1.0.8) (2.13.6)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.12/site-packages (from ibm-watsonx-ai==1.0.8) (8.6.1)\n",
      "Requirement already satisfied: ibm-cos-sdk-core==2.13.6 in /home/jupyterlab/.local/lib/python3.12/site-packages (from ibm-cos-sdk<2.14.0,>=2.12.0->ibm-watsonx-ai==1.0.8) (2.13.6)\n",
      "Requirement already satisfied: ibm-cos-sdk-s3transfer==2.13.6 in /home/jupyterlab/.local/lib/python3.12/site-packages (from ibm-cos-sdk<2.14.0,>=2.12.0->ibm-watsonx-ai==1.0.8) (2.13.6)\n",
      "Requirement already satisfied: jmespath<=1.0.1,>=0.10.0 in /home/jupyterlab/.local/lib/python3.12/site-packages (from ibm-cos-sdk<2.14.0,>=2.12.0->ibm-watsonx-ai==1.0.8) (1.0.1)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.9.0 in /opt/conda/lib/python3.12/site-packages (from ibm-cos-sdk-core==2.13.6->ibm-cos-sdk<2.14.0,>=2.12.0->ibm-watsonx-ai==1.0.8) (2.9.0.post0)\n",
      "Requirement already satisfied: numpy<2,>=1.26.0 in /home/jupyterlab/.local/lib/python3.12/site-packages (from pandas<2.2.0,>=0.24.2->ibm-watsonx-ai==1.0.8) (1.26.4)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.12/site-packages (from pandas<2.2.0,>=0.24.2->ibm-watsonx-ai==1.0.8) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/jupyterlab/.local/lib/python3.12/site-packages (from pandas<2.2.0,>=0.24.2->ibm-watsonx-ai==1.0.8) (2025.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.12/site-packages (from requests->ibm-watsonx-ai==1.0.8) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.12/site-packages (from requests->ibm-watsonx-ai==1.0.8) (3.10)\n",
      "Requirement already satisfied: zipp>=3.20 in /opt/conda/lib/python3.12/site-packages (from importlib-metadata->ibm-watsonx-ai==1.0.8) (3.21.0)\n",
      "Requirement already satisfied: six>=1.10.0 in /opt/conda/lib/python3.12/site-packages (from lomond->ibm-watsonx-ai==1.0.8) (1.17.0)\n",
      "Requirement already satisfied: langchain==0.2.11 in /home/jupyterlab/.local/lib/python3.12/site-packages (0.2.11)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/conda/lib/python3.12/site-packages (from langchain==0.2.11) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/conda/lib/python3.12/site-packages (from langchain==0.2.11) (2.0.37)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/conda/lib/python3.12/site-packages (from langchain==0.2.11) (3.11.18)\n",
      "Requirement already satisfied: langchain-core<0.3.0,>=0.2.23 in /home/jupyterlab/.local/lib/python3.12/site-packages (from langchain==0.2.11) (0.2.43)\n",
      "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /home/jupyterlab/.local/lib/python3.12/site-packages (from langchain==0.2.11) (0.2.4)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /home/jupyterlab/.local/lib/python3.12/site-packages (from langchain==0.2.11) (0.1.147)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.26.0 in /home/jupyterlab/.local/lib/python3.12/site-packages (from langchain==0.2.11) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /opt/conda/lib/python3.12/site-packages (from langchain==0.2.11) (2.10.6)\n",
      "Requirement already satisfied: requests<3,>=2 in /home/jupyterlab/.local/lib/python3.12/site-packages (from langchain==0.2.11) (2.32.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /home/jupyterlab/.local/lib/python3.12/site-packages (from langchain==0.2.11) (8.5.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/conda/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.11) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.11) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.11) (25.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.11) (1.6.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.11) (6.4.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/conda/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.11) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/conda/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.11) (1.20.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/lib/python3.12/site-packages (from langchain-core<0.3.0,>=0.2.23->langchain==0.2.11) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /opt/conda/lib/python3.12/site-packages (from langchain-core<0.3.0,>=0.2.23->langchain==0.2.11) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /opt/conda/lib/python3.12/site-packages (from langchain-core<0.3.0,>=0.2.23->langchain==0.2.11) (4.12.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/conda/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.2.11) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /home/jupyterlab/.local/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.2.11) (3.11.2)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /home/jupyterlab/.local/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.2.11) (1.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.12/site-packages (from pydantic<3,>=1->langchain==0.2.11) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /opt/conda/lib/python3.12/site-packages (from pydantic<3,>=1->langchain==0.2.11) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.12/site-packages (from requests<3,>=2->langchain==0.2.11) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.12/site-packages (from requests<3,>=2->langchain==0.2.11) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.12/site-packages (from requests<3,>=2->langchain==0.2.11) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.12/site-packages (from requests<3,>=2->langchain==0.2.11) (2024.12.14)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.12/site-packages (from SQLAlchemy<3,>=1.4->langchain==0.2.11) (3.1.1)\n",
      "Requirement already satisfied: anyio in /opt/conda/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.2.11) (4.8.0)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.2.11) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.2.11) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.23->langchain==0.2.11) (3.0.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.12/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.2.11) (1.3.1)\n",
      "Requirement already satisfied: langchain-ibm==0.1.7 in /home/jupyterlab/.local/lib/python3.12/site-packages (0.1.7)\n",
      "Requirement already satisfied: ibm-watsonx-ai<2.0.0,>=1.0.1 in /home/jupyterlab/.local/lib/python3.12/site-packages (from langchain-ibm==0.1.7) (1.0.8)\n",
      "Requirement already satisfied: langchain-core<0.3,>=0.1.50 in /home/jupyterlab/.local/lib/python3.12/site-packages (from langchain-ibm==0.1.7) (0.2.43)\n",
      "Requirement already satisfied: requests in /home/jupyterlab/.local/lib/python3.12/site-packages (from ibm-watsonx-ai<2.0.0,>=1.0.1->langchain-ibm==0.1.7) (2.32.2)\n",
      "Requirement already satisfied: urllib3 in /opt/conda/lib/python3.12/site-packages (from ibm-watsonx-ai<2.0.0,>=1.0.1->langchain-ibm==0.1.7) (2.3.0)\n",
      "Requirement already satisfied: pandas<2.2.0,>=0.24.2 in /home/jupyterlab/.local/lib/python3.12/site-packages (from ibm-watsonx-ai<2.0.0,>=1.0.1->langchain-ibm==0.1.7) (2.1.4)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.12/site-packages (from ibm-watsonx-ai<2.0.0,>=1.0.1->langchain-ibm==0.1.7) (2024.12.14)\n",
      "Requirement already satisfied: lomond in /home/jupyterlab/.local/lib/python3.12/site-packages (from ibm-watsonx-ai<2.0.0,>=1.0.1->langchain-ibm==0.1.7) (0.3.3)\n",
      "Requirement already satisfied: tabulate in /home/jupyterlab/.local/lib/python3.12/site-packages (from ibm-watsonx-ai<2.0.0,>=1.0.1->langchain-ibm==0.1.7) (0.9.0)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.12/site-packages (from ibm-watsonx-ai<2.0.0,>=1.0.1->langchain-ibm==0.1.7) (24.2)\n",
      "Requirement already satisfied: ibm-cos-sdk<2.14.0,>=2.12.0 in /home/jupyterlab/.local/lib/python3.12/site-packages (from ibm-watsonx-ai<2.0.0,>=1.0.1->langchain-ibm==0.1.7) (2.13.6)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.12/site-packages (from ibm-watsonx-ai<2.0.0,>=1.0.1->langchain-ibm==0.1.7) (8.6.1)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/conda/lib/python3.12/site-packages (from langchain-core<0.3,>=0.1.50->langchain-ibm==0.1.7) (6.0.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/lib/python3.12/site-packages (from langchain-core<0.3,>=0.1.50->langchain-ibm==0.1.7) (1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.112 in /home/jupyterlab/.local/lib/python3.12/site-packages (from langchain-core<0.3,>=0.1.50->langchain-ibm==0.1.7) (0.1.147)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /opt/conda/lib/python3.12/site-packages (from langchain-core<0.3,>=0.1.50->langchain-ibm==0.1.7) (2.10.6)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /home/jupyterlab/.local/lib/python3.12/site-packages (from langchain-core<0.3,>=0.1.50->langchain-ibm==0.1.7) (8.5.0)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /opt/conda/lib/python3.12/site-packages (from langchain-core<0.3,>=0.1.50->langchain-ibm==0.1.7) (4.12.2)\n",
      "Requirement already satisfied: ibm-cos-sdk-core==2.13.6 in /home/jupyterlab/.local/lib/python3.12/site-packages (from ibm-cos-sdk<2.14.0,>=2.12.0->ibm-watsonx-ai<2.0.0,>=1.0.1->langchain-ibm==0.1.7) (2.13.6)\n",
      "Requirement already satisfied: ibm-cos-sdk-s3transfer==2.13.6 in /home/jupyterlab/.local/lib/python3.12/site-packages (from ibm-cos-sdk<2.14.0,>=2.12.0->ibm-watsonx-ai<2.0.0,>=1.0.1->langchain-ibm==0.1.7) (2.13.6)\n",
      "Requirement already satisfied: jmespath<=1.0.1,>=0.10.0 in /home/jupyterlab/.local/lib/python3.12/site-packages (from ibm-cos-sdk<2.14.0,>=2.12.0->ibm-watsonx-ai<2.0.0,>=1.0.1->langchain-ibm==0.1.7) (1.0.1)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.9.0 in /opt/conda/lib/python3.12/site-packages (from ibm-cos-sdk-core==2.13.6->ibm-cos-sdk<2.14.0,>=2.12.0->ibm-watsonx-ai<2.0.0,>=1.0.1->langchain-ibm==0.1.7) (2.9.0.post0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3,>=0.1.50->langchain-ibm==0.1.7) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/conda/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.112->langchain-core<0.3,>=0.1.50->langchain-ibm==0.1.7) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /home/jupyterlab/.local/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.112->langchain-core<0.3,>=0.1.50->langchain-ibm==0.1.7) (3.11.2)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /home/jupyterlab/.local/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.112->langchain-core<0.3,>=0.1.50->langchain-ibm==0.1.7) (1.0.0)\n",
      "Requirement already satisfied: numpy<2,>=1.26.0 in /home/jupyterlab/.local/lib/python3.12/site-packages (from pandas<2.2.0,>=0.24.2->ibm-watsonx-ai<2.0.0,>=1.0.1->langchain-ibm==0.1.7) (1.26.4)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.12/site-packages (from pandas<2.2.0,>=0.24.2->ibm-watsonx-ai<2.0.0,>=1.0.1->langchain-ibm==0.1.7) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/jupyterlab/.local/lib/python3.12/site-packages (from pandas<2.2.0,>=0.24.2->ibm-watsonx-ai<2.0.0,>=1.0.1->langchain-ibm==0.1.7) (2025.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<0.3,>=0.1.50->langchain-ibm==0.1.7) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /opt/conda/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<0.3,>=0.1.50->langchain-ibm==0.1.7) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.12/site-packages (from requests->ibm-watsonx-ai<2.0.0,>=1.0.1->langchain-ibm==0.1.7) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.12/site-packages (from requests->ibm-watsonx-ai<2.0.0,>=1.0.1->langchain-ibm==0.1.7) (3.10)\n",
      "Requirement already satisfied: zipp>=3.20 in /opt/conda/lib/python3.12/site-packages (from importlib-metadata->ibm-watsonx-ai<2.0.0,>=1.0.1->langchain-ibm==0.1.7) (3.21.0)\n",
      "Requirement already satisfied: six>=1.10.0 in /opt/conda/lib/python3.12/site-packages (from lomond->ibm-watsonx-ai<2.0.0,>=1.0.1->langchain-ibm==0.1.7) (1.17.0)\n",
      "Requirement already satisfied: anyio in /opt/conda/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.112->langchain-core<0.3,>=0.1.50->langchain-ibm==0.1.7) (4.8.0)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.112->langchain-core<0.3,>=0.1.50->langchain-ibm==0.1.7) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.112->langchain-core<0.3,>=0.1.50->langchain-ibm==0.1.7) (0.14.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.12/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.112->langchain-core<0.3,>=0.1.50->langchain-ibm==0.1.7) (1.3.1)\n",
      "Requirement already satisfied: langchain-core==0.2.43 in /home/jupyterlab/.local/lib/python3.12/site-packages (0.2.43)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/conda/lib/python3.12/site-packages (from langchain-core==0.2.43) (6.0.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/lib/python3.12/site-packages (from langchain-core==0.2.43) (1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.112 in /home/jupyterlab/.local/lib/python3.12/site-packages (from langchain-core==0.2.43) (0.1.147)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /opt/conda/lib/python3.12/site-packages (from langchain-core==0.2.43) (24.2)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /opt/conda/lib/python3.12/site-packages (from langchain-core==0.2.43) (2.10.6)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /home/jupyterlab/.local/lib/python3.12/site-packages (from langchain-core==0.2.43) (8.5.0)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /opt/conda/lib/python3.12/site-packages (from langchain-core==0.2.43) (4.12.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core==0.2.43) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/conda/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.112->langchain-core==0.2.43) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /home/jupyterlab/.local/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.112->langchain-core==0.2.43) (3.11.2)\n",
      "Requirement already satisfied: requests<3,>=2 in /home/jupyterlab/.local/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.112->langchain-core==0.2.43) (2.32.2)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /home/jupyterlab/.local/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.112->langchain-core==0.2.43) (1.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core==0.2.43) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /opt/conda/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core==0.2.43) (2.27.2)\n",
      "Requirement already satisfied: anyio in /opt/conda/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.112->langchain-core==0.2.43) (4.8.0)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.112->langchain-core==0.2.43) (2024.12.14)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.112->langchain-core==0.2.43) (1.0.7)\n",
      "Requirement already satisfied: idna in /opt/conda/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.112->langchain-core==0.2.43) (3.10)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.112->langchain-core==0.2.43) (0.14.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.12/site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.112->langchain-core==0.2.43) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.12/site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.112->langchain-core==0.2.43) (2.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.12/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.112->langchain-core==0.2.43) (1.3.1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!pip install \"ibm-watsonx-ai==1.0.8\" --user\n",
    "!pip install \"langchain==0.2.11\" --user\n",
    "!pip install \"langchain-ibm==0.1.7\" --user\n",
    "!pip install \"langchain-core==0.2.43\" --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0d449d8-f555-4cbd-a188-56265eaa0784",
   "metadata": {},
   "outputs": [],
   "source": [
    "# suppress warnings generated by your code:\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# IBM WatsonX imports\n",
    "from ibm_watsonx_ai.foundation_models import Model\n",
    "from ibm_watsonx_ai.metanames import GenTextParamsMetaNames as GenParams\n",
    "from ibm_watsonx_ai.foundation_models.utils.enums import ModelTypes\n",
    "\n",
    "from langchain_ibm import WatsonxLLM\n",
    "from langchain_core.prompts import PromptTemplate, ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableSequence\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain.chains import LLMChain  # Still using this for backward compatibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36db864c-fed4-4509-8661-369c1bc5b7d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'decoding_method': 'sample',\n",
       " 'length_penalty': {'decay_factor': 2.5, 'start_index': 5},\n",
       " 'temperature': 0.5,\n",
       " 'top_p': 0.2,\n",
       " 'top_k': 1,\n",
       " 'random_seed': 33,\n",
       " 'repetition_penalty': 2,\n",
       " 'min_new_tokens': 50,\n",
       " 'max_new_tokens': 200,\n",
       " 'stop_sequences': ['fail'],\n",
       " ' time_limit': 600000,\n",
       " 'truncate_input_tokens': 200,\n",
       " 'prompt_variables': {'object': 'brain'},\n",
       " 'return_options': {'input_text': True,\n",
       "  'generated_tokens': True,\n",
       "  'input_tokens': True,\n",
       "  'token_logprobs': True,\n",
       "  'token_ranks': False,\n",
       "  'top_n_tokens': False}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GenParams().get_example_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01442164-4f53-4119-9067-ad29aa1d5b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm_model(prompt_txt, params=None):\n",
    "    \n",
    "    model_id = \"ibm/granite-3-2-8b-instruct\"\n",
    "\n",
    "    default_params = {\n",
    "        \"max_new_tokens\": 256,\n",
    "        \"min_new_tokens\": 0,\n",
    "        \"temperature\": 0.5,\n",
    "        \"top_p\": 0.2,\n",
    "        \"top_k\": 1\n",
    "    }\n",
    "\n",
    "    url = \"https://us-south.ml.cloud.ibm.com\"\n",
    "    project_id = \"skills-network\"\n",
    "    \n",
    "    granite_llm = WatsonxLLM(\n",
    "        model_id=model_id,\n",
    "        project_id=project_id,\n",
    "        url=url,\n",
    "        params=params\n",
    "    )\n",
    "    \n",
    "    response = granite_llm.invoke(prompt_txt)\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "690209e8-2212-4357-b850-75270eb2cc83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt: The future of artificial intelligence is\n",
      "\n",
      "response :  a topic of great interest and debate. Here are some key aspects and predictions about the future of AI:\n",
      "\n",
      "1. **Advancements in Machine Learning and Deep Learning**: AI will continue to improve in its ability to learn from data, make predictions, and improve its performance over time. This includes advancements in reinforcement learning, unsupervised learning, and transfer learning.\n",
      "\n",
      "2. **Explainable AI (XAI)**: As AI systems become more complex, there's a growing need for them to be explainable. This means developing AI that can provide clear explanations for its decisions, which is crucial\n",
      "\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    \"max_new_tokens\": 128,\n",
    "    \"min_new_tokens\": 10,\n",
    "    \"temperature\": 0.5,\n",
    "    \"top_p\": 0.2,\n",
    "    \"top_k\": 1\n",
    "}\n",
    "\n",
    "prompt = \"The future of artificial intelligence is\"\n",
    "\n",
    "# Getting a reponse from the model with the provided prompt and new parameters\n",
    "response = llm_model(prompt, params)\n",
    "print(f\"prompt: {prompt}\\n\")\n",
    "print(f\"response : {response}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e34a1e1-2859-4833-893a-a465e9f4f363",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt: Classify the following statement as true or false: \n",
      "            'The Eiffel Tower is located in Berlin.'\n",
      "\n",
      "            Answer:\n",
      "\n",
      "\n",
      "response : \n",
      "False. The Eiffel Tower is located in Paris, France.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"Classify the following statement as true or false: \n",
    "            'The Eiffel Tower is located in Berlin.'\n",
    "\n",
    "            Answer:\n",
    "\"\"\"\n",
    "response = llm_model(prompt, params)\n",
    "print(f\"prompt: {prompt}\\n\")\n",
    "print(f\"response : {response}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ec7b35b-2b0c-4907-bb32-c318fe6359c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== MOVIE_REVIEW RESPONSE ===\n",
      "\n",
      "Step 1: Identify the sentiment expressed in the review.\n",
      "- The reviewer expresses disappointment, dissatisfaction, and negative opinions about various aspects of the film.\n",
      "\n",
      "Step 2: Analyze the language used in the review.\n",
      "- Words like \"extremely disappointed,\" \"predictable,\" \"wooden,\" \"cheap,\" and \"can't recommend\" convey a negative sentiment.\n",
      "\n",
      "Step 3: Consider the overall tone of the review.\n",
      "- The tone is critical and dismissive, indicating a strong negative opinion of the film.\n",
      "\n",
      "Step \n",
      "\n",
      "=== CLIMATE_CHANGE RESPONSE ===\n",
      "Climate change denotes long-term alterations in temperature and weather patterns, predominantly caused by human activities since the 1800s, particularly the burning of fossil fuels that emit heat-trapping gases. This leads to increased frequency and intensity of extreme weather events, rising sea levels, melting glaciers, and warming oceans, all of which threaten biodiversity, agriculture, and human health.\n",
      "\n",
      "=== TRANSLATION RESPONSE ===\n",
      "\n",
      "\"Me gustaría pedir un café con leche y dos azúcares, por favor.\"\n",
      "\n",
      "Explanation:\n",
      "\n",
      "- \"I would like to order\" translates to \"Me gustaría pedir\" in Spanish.\n",
      "- \"a coffee\" translates to \"un café\" in Spanish.\n",
      "- \"with milk\" translates to \"con leche\" in Spanish.\n",
      "- \"and\" translates to \"y\" in Spanish.\n",
      "- \"two sugars\" translates to \"dos azúcares\" in\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1. Prompt for Movie Review Classification\n",
    "movie_review_prompt = \"\"\"\n",
    "Classify the following movie review as either 'positive' or 'negative'.\n",
    "\n",
    "Review: \"I was extremely disappointed by this film. The plot was predictable, the acting was wooden, and the special effects looked cheap. I can't recommend this to anyone.\"\n",
    "\n",
    "Classification:\n",
    "\"\"\"\n",
    "\n",
    "# 2. Prompt for Climate Change Paragraph Summarization\n",
    "climate_change_prompt = \"\"\"\n",
    "Summarize the following paragraph about climate change in no more than two sentences.\n",
    "\n",
    "Paragraph: \"Climate change refers to long-term shifts in temperatures and weather patterns. These shifts may be natural, but since the 1800s, human activities have been the main driver of climate change, primarily due to the burning of fossil fuels like coal, oil and gas, which produces heat-trapping gases. The consequences of climate change include more frequent and severe droughts, storms, and heat waves, rising sea levels, melting glaciers, and warming oceans which can directly impact biodiversity, agriculture, and human health.\"\n",
    "\n",
    "Summary:\n",
    "\"\"\"\n",
    "\n",
    "# 3. Prompt for English to Spanish Translation\n",
    "translation_prompt = \"\"\"\n",
    "Translate the following English phrase into Spanish.\n",
    "\n",
    "English: \"I would like to order a coffee with milk and two sugars, please.\"\n",
    "\n",
    "Spanish:\n",
    "\"\"\"\n",
    "responses = {}\n",
    "responses[\"movie_review\"] = llm_model(movie_review_prompt, params)\n",
    "responses[\"climate_change\"] = llm_model(climate_change_prompt, params)\n",
    "responses[\"translation\"] = llm_model(translation_prompt, params)\n",
    "\n",
    "for prompt_type, response in responses.items():\n",
    "    print(f\"=== {prompt_type.upper()} RESPONSE ===\")\n",
    "    print(response)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b6f39608-e49c-4138-8ff5-c889b9fa1802",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt: Here is an example of translating a sentence from English to French:\n",
      "\n",
      "            English: “How is the weather today?”\n",
      "            French: “Comment est le temps aujourd'hui?”\n",
      "            \n",
      "            Now, translate the following sentence from English to French:\n",
      "            \n",
      "            English: “Where is the nearest supermarket?”\n",
      "            \n",
      "\n",
      "\n",
      "response : French: “Où est le supermarché le plus proche?”\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    \"max_new_tokens\": 20,\n",
    "    \"temperature\": 0.1,\n",
    "}\n",
    "\n",
    "prompt = \"\"\"Here is an example of translating a sentence from English to French:\n",
    "\n",
    "            English: “How is the weather today?”\n",
    "            French: “Comment est le temps aujourd'hui?”\n",
    "            \n",
    "            Now, translate the following sentence from English to French:\n",
    "            \n",
    "            English: “Where is the nearest supermarket?”\n",
    "            \n",
    "\"\"\"\n",
    "response = llm_model(prompt, params)\n",
    "print(f\"prompt: {prompt}\\n\")\n",
    "print(f\"response : {response}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "87ad8ddf-7110-4334-9d66-dd2b68c6eaa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt: Here are few examples of classifying emotions in statements:\n",
      "\n",
      "           Statement: 'I just won my first marathon!'\n",
      "           Emotion: Joy\n",
      "           \n",
      "           Statement: 'I can't believe I lost my keys again.'\n",
      "           Emotion: Frustration\n",
      "           \n",
      "           Statement: 'My best friend is moving to another country.'\n",
      "           Emotion: Sadness\n",
      "           \n",
      "           Now, classify the emotion in the following statement:\n",
      "           Statement: 'That movie was so scary I had to cover my eyes.’\n",
      "           \n",
      "\n",
      "\n",
      "\n",
      "response :  Emotion: Fear\n",
      "\n"
     ]
    }
   ],
   "source": [
    " #parameters  `max_new_tokens` to 10, which constrains the model to generate brief responses\n",
    "\n",
    "params = {\n",
    "    \"max_new_tokens\": 10,\n",
    "}\n",
    "\n",
    "prompt = \"\"\"Here are few examples of classifying emotions in statements:\n",
    "\n",
    "            Statement: 'I just won my first marathon!'\n",
    "            Emotion: Joy\n",
    "            \n",
    "            Statement: 'I can't believe I lost my keys again.'\n",
    "            Emotion: Frustration\n",
    "            \n",
    "            Statement: 'My best friend is moving to another country.'\n",
    "            Emotion: Sadness\n",
    "            \n",
    "            Now, classify the emotion in the following statement:\n",
    "            Statement: 'That movie was so scary I had to cover my eyes.’\n",
    "            \n",
    "\n",
    "\"\"\"\n",
    "response = llm_model(prompt, params)\n",
    "print(f\"prompt: {prompt}\\n\")\n",
    "print(f\"response : {response}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e4af685b-bd2c-4a6f-848f-d006216ead13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt: Consider the problem: 'A store had 22 apples. They sold 15 apples today and got a new delivery of 8 apples. \n",
      "            How many apples are there now?’\n",
      "\n",
      "            Break down each step of your calculation\n",
      "\n",
      "\n",
      "\n",
      "response : \n",
      "1. Identify the initial quantity of apples: The store started with 22 apples.\n",
      "2. Determine the number of apples sold: They sold 15 apples today.\n",
      "3. Calculate the remaining apples after sales: 22 - 15 = 7 apples.\n",
      "4. Identify the new delivery of apples: They received a delivery of 8 apples.\n",
      "5. Calculate the total number of apples now: 7 (remaining) + 8 (new delivery) = 15 apples.\n",
      "\n",
      "So, there are now 15 apples in the store.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    \"max_new_tokens\": 512,\n",
    "    \"temperature\": 0.5,\n",
    "}\n",
    "\n",
    "prompt = \"\"\"Consider the problem: 'A store had 22 apples. They sold 15 apples today and got a new delivery of 8 apples. \n",
    "            How many apples are there now?’\n",
    "\n",
    "            Break down each step of your calculation\n",
    "\n",
    "\"\"\"\n",
    "response = llm_model(prompt, params)\n",
    "print(f\"prompt: {prompt}\\n\")\n",
    "print(f\"response : {response}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c8c37fce-77b1-4365-9052-5c4c2c82e83b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt: When I was 6, my sister was half of my age. Now I am 70, what age is my sister?\n",
      "\n",
      "            Provide three independent calculations and explanations, then determine the most consistent result.\n",
      "\n",
      "\n",
      "\n",
      "response :  Calculation 1:\n",
      "When I was 6, my sister was half my age, so she was 6 / 2 = 3 years old.\n",
      "Now, 70 - 3 = 67 years old.\n",
      "\n",
      "Calculation 2:\n",
      "If my sister was 3 when I was 6, then she is 6 - 3 = 3 years younger than me.\n",
      "Now, 70 - 3 = 67 years old.\n",
      "\n",
      "Calculation 3:\n",
      "My sister was 3 when I was 6, so she is 3 years younger than me.\n",
      "Now, 70 - 3 = 67 years old.\n",
      "\n",
      "All three calculations show that my sister is 67 years old now. This is the most consistent result, as it is derived from the same initial information and applies the same logic in each calculation.\n",
      "\n",
      "Final answer: My sister is 67 years old.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    \"max_new_tokens\": 512,\n",
    "}\n",
    "\n",
    "prompt = \"\"\"When I was 6, my sister was half of my age. Now I am 70, what age is my sister?\n",
    "\n",
    "            Provide three independent calculations and explanations, then determine the most consistent result.\n",
    "\n",
    "\"\"\"\n",
    "response = llm_model(prompt, params)\n",
    "print(f\"prompt: {prompt}\\n\")\n",
    "print(f\"response : {response}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6ed2aaf5-2436-4157-8fb8-a28ea64b23b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WatsonxLLM(model_id='meta-llama/llama-3-3-70b-instruct', project_id='skills-network', url=SecretStr('**********'), apikey=SecretStr('**********'), params={'max_new_tokens': 256, 'temperature': 0.5}, watsonx_model=<ibm_watsonx_ai.foundation_models.inference.model_inference.ModelInference object at 0x79675c8b95e0>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_id = \"meta-llama/llama-3-3-70b-instruct\"\n",
    "\n",
    "parameters = {\n",
    "    GenParams.MAX_NEW_TOKENS: 256,  # this controls the maximum number of tokens in the generated output\n",
    "    GenParams.TEMPERATURE: 0.5, # this randomness or creativity of the model's responses\n",
    "}\n",
    "\n",
    "url = \"https://us-south.ml.cloud.ibm.com\"\n",
    "project_id = \"skills-network\"\n",
    "\n",
    "llm = WatsonxLLM(\n",
    "        model_id=model_id,\n",
    "        url=url,\n",
    "        project_id=project_id,\n",
    "        params=parameters\n",
    "    )\n",
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dad93fb8-a34d-408a-afdf-d118b1f3caea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['adjective', 'content'], template='Tell me a {adjective} joke about {content}.\\n')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template = \"\"\"Tell me a {adjective} joke about {content}.\n",
    "\"\"\"\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "prompt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "848f4224-a92c-45bf-9722-289b8d887871",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "# Define a function to ensure proper formatting\n",
    "def format_prompt(variables):\n",
    "    return prompt.format(**variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "41300e36-c395-4ba3-ab64-9871b1f42437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why did the chicken go to the doctor?\n",
      "Because it had fowl breath! (get it? like \"foul\" breath, but \"fowl\" like a chicken!)\n",
      "Hope that made you cluck with laughter! Do you want to hear another one? \n",
      "Why did the chicken go to the gym?\n",
      "To get some egg-cellent abs!\n",
      "Hope that one cracked you up! Do you want to hear another one? \n",
      "Why did the chicken go to the beauty parlor?\n",
      "To get a beak trim and some egg-stra special highlights!\n",
      "Hope that one made you squawk with laughter! Do you want to hear another one? \n",
      "Why did the chicken go to therapy?\n",
      "Because it was having some fowl mood swings!\n",
      "Hope that one made you cluck with amusement! Do you want to hear another one? \n",
      "Why did the chicken go to the talent agent?\n",
      "Because it wanted to be a star and scratch out a career in showbiz!\n",
      "Hope that one made you peck with excitement! Do you want to hear another one? \n",
      "Why did the chicken go to the dance club?\n",
      "To bust a move and get its beak on the dance floor!\n",
      "Hope that one made you flap with fun! Do you want to hear another one? \n",
      "Why\n"
     ]
    }
   ],
   "source": [
    "# Create the chain with explicit formatting\n",
    "joke_chain = (\n",
    "    RunnableLambda(format_prompt)\n",
    "    | llm \n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# Run the chain\n",
    "response = joke_chain.invoke({\"adjective\": \"funny\", \"content\": \"chickens\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cdb65a60-38fd-4098-a010-740cc39d425e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ```sql\n",
      "    SELECT c.name, c.email \n",
      "    FROM customers c \n",
      "    JOIN purchases p ON c.customer_id = p.customer_id \n",
      "    WHERE p.purchase_date >= NOW() - INTERVAL 30 DAY;\n",
      "    ```\n",
      "\n",
      "### Explanation\n",
      "\n",
      "*   We start by selecting the columns we want to retrieve, which are `name` and `email`, from the `customers` table.\n",
      "*   We use an inner join to combine rows from the `customers` and `purchases` tables where the `customer_id` matches.\n",
      "*   The `WHERE` clause filters the results to include only rows where the `purchase_date` is within the last 30 days. The `NOW()` function returns the current date and time, and `INTERVAL 30 DAY` subtracts 30 days from it.\n",
      "\n",
      "### Example Use Case\n",
      "\n",
      "Suppose we have the following data in our tables:\n",
      "\n",
      "**customers table:**\n",
      "\n",
      "| customer\\_id | name | email          |\n",
      "| ------------ | ---- | -------------- |\n",
      "| 1            | John | john@example   |\n",
      "| 2            | Jane | jane@example   |\n",
      "| 3            | Joe  | joe@example    |\n",
      "\n",
      "**purchases table:**\n",
      "\n",
      "| purchase\\_id | customer\\_id | purchase\\_date |\n",
      "\n"
     ]
    }
   ],
   "source": [
    "description = \"\"\"\n",
    "    Retrieve the names and email addresses of all customers from the 'customers' table who have made a purchase in the last 30 days. \n",
    "    The table 'purchases' contains a column 'purchase_date'\n",
    "\"\"\"\n",
    "\n",
    "template = \"\"\"\n",
    "    Generate an SQL query based on the {description}\n",
    "    \n",
    "    SQL Query:\n",
    "    \n",
    "\"\"\"\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "# Create the LCEL chain\n",
    "sql_generation_chain = (\n",
    "    RunnableLambda(format_prompt) \n",
    "    | llm \n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# Run the chain\n",
    "sql_query = sql_generation_chain.invoke({\"description\": description})\n",
    "print(sql_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18403127-4269-471b-bff4-eb4cff10c7a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
